{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "059007f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful!\n",
      "Checksum: 04318a24fe9bea7df4dbcc76c88611c16042ec268c77189f766f666c5fc3de43\n"
     ]
    }
   ],
   "source": [
    "## NOAA GSOM DATA \n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import time \n",
    "import os\n",
    "\n",
    "#request API token from https://www.ncdc.noaa.gov/cdo-web/token\n",
    "NOAA_TOKEN = \"LPNBoLnCBrwwGQMWwLMlAQjEmoagiRqi\"\n",
    "BASE_URL = \"https://www.ncei.noaa.gov/access/services/data/v1\"\n",
    "\n",
    "#define our parameters to be used \n",
    "dataset = \"global-summary-of-the-month\"\n",
    "station_id=\"USC00118740\"\n",
    "end_date=\"2025-10-31\"\n",
    "start_date=\"1902-08-01\"\n",
    "format=\"csv\"\n",
    "\n",
    "\n",
    "OUTPUT_FILENAME = f\"{station_id}_GSOM_{start_date}_to_{end_date}.csv\"\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_dir = os.path.join(project_root, \"data\", \"raw\")\n",
    "docs_dir = os.path.join(project_root, \"documentation\")\n",
    "\n",
    "output_path = os.path.join(data_dir, OUTPUT_FILENAME)\n",
    "metadata_path = os.path.join(docs_dir, \"gsom_data_acquisition.txt\")\n",
    "\n",
    "#create directories if needed for user\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(docs_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"dataset\":   dataset,\n",
    "    \"stations\":  station_id,\n",
    "    \"startDate\": start_date,\n",
    "    \"endDate\":   end_date,\n",
    "    \"format\":    format,\n",
    "}\n",
    "headers = {\"token\": NOAA_TOKEN}\n",
    "\n",
    "#define our checksum \n",
    "def compute_sha256(file_path):\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(chunk)\n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "\n",
    "try:\n",
    "    response = requests.get(BASE_URL, params=params, headers=headers, timeout=60)\n",
    "    response.raise_for_status()\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"Request timed out. Try again or check your connection.\")\n",
    "    raise\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    print(f\"HTTP error occurred: {http_err}\")\n",
    "    print(f\"Response content: {response.text[:300]} ...\")\n",
    "    raise\n",
    "except Exception as err:\n",
    "    print(f\"Other error occurred: {err}\")\n",
    "    raise\n",
    "else:\n",
    "    print(\"Request successful!\")\n",
    "\n",
    "\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "checksum = compute_sha256(output_path)\n",
    "print(f\"Checksum: {checksum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dce3528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows\n",
      "       STATION     DATE  ADPT  ASLP  ASTP  AWBT  AWND  CDSD  CLDD  DP01  ...  \\\n",
      "0  USC00118740  1902-08   NaN   NaN   NaN   NaN   NaN   NaN  96.0   8.0  ...   \n",
      "1  USC00118740  1902-09   NaN   NaN   NaN   NaN   NaN   NaN  22.9   9.0  ...   \n",
      "2  USC00118740  1902-10   NaN   NaN   NaN   NaN   NaN   NaN   3.3   6.0  ...   \n",
      "3  USC00118740  1902-11   NaN   NaN   NaN   NaN   NaN   NaN   0.3   8.0  ...   \n",
      "4  USC00118740  1902-12   NaN   NaN   NaN   NaN   NaN   NaN   0.0  12.0  ...   \n",
      "\n",
      "   WDF2  WDF5  WDFG  WDFM  WDMV  WSF1  WSF2  WSF5  WSFG  WSFM  \n",
      "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "1   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[5 rows x 150 columns]\n",
      "Number of records 1479\n"
     ]
    }
   ],
   "source": [
    "# NOAA GSOM DF \n",
    "df = pd.read_csv(output_path)\n",
    "print(\"\\nFirst 5 rows\")\n",
    "print(df.head())\n",
    "print(f\"Number of records {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA GSOM METADATA\n",
    "metadata = f\"\"\"\n",
    "Date Retrieved: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}\n",
    "Dataset: {dataset}\n",
    "Station ID: {station_id}\n",
    "Station Name: Champaign 3 S, IL US\n",
    "Period of Record: {start_date} to {end_date}\n",
    "Source URL: {BASE_URL}\n",
    "Local File: {output_path}\n",
    "File SHA-256 Checksum: {checksum}\n",
    "\n",
    "Reproduction Instructions:\n",
    "1. Request an API token from https://www.ncdc.noaa.gov/cdo-web/token\n",
    "2. Run the above GSOM_Acquisition.ipynb Notebook cells with the same parameters\n",
    "3. Verify the resulting file's integrity using:\n",
    "bash\n",
    "$ shasum -a 256 {OUTPUT_FILENAME}\n",
    "\n",
    "The output hash should match:\n",
    "{checksum}\n",
    "\n",
    "Notes:\n",
    "- This data is saved to 'data/raw' for our pipeline\n",
    "- Metadata and checksum documentation are stored in '/documentation'\n",
    "\"\"\"\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    f.write(metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
